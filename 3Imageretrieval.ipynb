{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3Imageretrieval.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dasalgadob/handson-machine-learning/blob/master/3Imageretrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c649-5QTOUdK",
        "colab_type": "code",
        "outputId": "9f7d2700-169a-4d8f-d62c-d4a7596603d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import stack\n",
        "#from keras.datasets import mnist\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from tensorflow.contrib.tensorboard.plugins import projector\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nwljkycRgSYq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vaaq3lAygCTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6174060-df88-4a09-f6ae-7a0013d9fc10"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorboardcolab"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lLZ8lwl8sudC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Chapter 1 Previous code to chapter 3"
      ]
    },
    {
      "metadata": {
        "id": "MuTdy6sFstSl",
        "colab_type": "code",
        "outputId": "32fa5d8f-4945-4117-f6b8-2bbe84ebaa10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "cell_type": "code",
      "source": [
        "## Loading\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-d7457694f99a>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gr8Xewc4s6ec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "no_classes = 10\n",
        "batch_size = 100\n",
        "total_batches = 400"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4c9jK_8CtbtL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Placeholders for input data and targets\n",
        "x_input = tf.placeholder(tf.float32, shape=[None, input_size])\n",
        "y_input = tf.placeholder(tf.float32, shape=[None, no_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zvB5k-pSt5E-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights = tf.Variable(tf.random_normal([input_size, no_classes]))\n",
        "bias = tf.Variable(tf.random_normal([no_classes]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RzmVOw5quVI0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logits = tf.matmul(x_input, weights) + bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "huNBlainuWJW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "softmax_cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "labels=y_input, logits=logits)\n",
        "loss_operation = tf.reduce_mean(softmax_cross_entropy)\n",
        "optimiser = tf.train.GradientDescentOptimizer(\n",
        "learning_rate=0.5).minimize(loss_operation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "elmWVX57uxEa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Training the model with data\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "\n",
        "for batch_no in range(total_batches):\n",
        "  mnist_batch = mnist_data.train.next_batch(batch_size)\n",
        "  _, loss_value = session.run([optimiser, loss_operation], feed_dict={\n",
        "  x_input: mnist_batch[0],\n",
        "  y_input: mnist_batch[1]\n",
        "  })\n",
        "  #print(loss_value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5VXajUGgvaLa",
        "colab_type": "code",
        "outputId": "49b8ebda-bd85-4746-aa2c-ad4863cc0210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = tf.argmax(logits, 1)\n",
        "correct_predictions = tf.equal(predictions, tf.argmax(y_input, 1))\n",
        "accuracy_operation = tf.reduce_mean(tf.cast(correct_predictions,\n",
        "tf.float32))\n",
        "test_images, test_labels = mnist_data.test.images, mnist_data.test.labels\n",
        "accuracy_value = session.run(accuracy_operation, feed_dict={\n",
        "x_input: test_images,\n",
        "y_input: test_labels\n",
        "})\n",
        "print('Accuracy : ', accuracy_value)\n",
        "session.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Iy96NWGWxFkc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Multilayer convolutional network\n",
        "\n",
        "def add_variable_summary(tf_variable, summary_name):\n",
        "  with tf.name_scope(summary_name + '_summary'):\n",
        "    mean = tf.reduce_mean(tf_variable)\n",
        "    tf.summary.scalar('Mean', mean)\n",
        "    with tf.name_scope('standard_deviation'):\n",
        "      standard_deviation = tf.sqrt(tf.reduce_mean( tf.square(tf_variable - mean)))\n",
        "    tf.summary.scalar('StandardDeviation', standard_deviation)\n",
        "    tf.summary.scalar('Maximum', tf.reduce_max(tf_variable))\n",
        "    tf.summary.scalar('Minimum', tf.reduce_min(tf_variable))\n",
        "    tf.summary.histogram('Histogram', tf_variable)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7BZwfJIpxoT1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_input_reshape = tf.reshape(x_input, [-1, 28, 28, 1],\n",
        "name='input_reshape') ## -1 refers that the batch size could be any"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vAcZZrgwy8j1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convolution_layer(input_layer, filters, kernel_size=[3, 3], activation=tf.nn.relu):\n",
        "  layer = tf.layers.conv2d(\n",
        "  inputs=input_layer,\n",
        "  filters=filters,\n",
        "  kernel_size=kernel_size,\n",
        "  activation=activation,\n",
        "  )\n",
        "  add_variable_summary(layer, 'convolution')\n",
        "  return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cgugcsodW7ex",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pooling_layer(input_layer, pool_size=[2, 2], strides=2):\n",
        "  layer = tf.layers.max_pooling2d(\n",
        "  inputs=input_layer,\n",
        "  pool_size=pool_size,\n",
        "  strides=strides\n",
        "  )\n",
        "  add_variable_summary(layer, 'pooling')\n",
        "  return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xcuk5I0qXPBx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dense_layer(input_layer, units, activation=tf.nn.relu):\n",
        "  layer = tf.layers.dense(\n",
        "  inputs=input_layer,\n",
        "  units=units,\n",
        "  activation=activation\n",
        "  )\n",
        "  add_variable_summary(layer, 'dense')\n",
        "  return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DWZs-tOvXcfc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "convolution_layer_1 = convolution_layer(x_input_reshape, 64)\n",
        "pooling_layer_1 = pooling_layer(convolution_layer_1)\n",
        "convolution_layer_2 = convolution_layer(pooling_layer_1, 128)\n",
        "pooling_layer_2 = pooling_layer(convolution_layer_2)\n",
        "flattened_pool = tf.reshape(pooling_layer_2, [-1, 5 * 5 * 128],\n",
        "name='flattened_pool')\n",
        "dense_layer_bottleneck = dense_layer(flattened_pool, 1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jBxOs93uX3uI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dropout_bool = tf.placeholder(tf.bool)\n",
        "dropout_layer = tf.layers.dropout(\n",
        "inputs=dense_layer_bottleneck,\n",
        "rate=0.4,\n",
        "training=dropout_bool\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hiGRBeO3ZMxR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logits = dense_layer(dropout_layer, no_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zI9seQeCZTyE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope('loss'):\n",
        "  softmax_cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "  labels=y_input, logits=logits)\n",
        "  loss_operation = tf.reduce_mean(softmax_cross_entropy, name='loss')\n",
        "  tf.summary.scalar('loss', loss_operation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VvYsMsrXZhaL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope('optimiser'):\n",
        "  optimiser = tf.train.AdamOptimizer().minimize(loss_operation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QuxrFy1EZm-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9ef7689-6c5e-4068-9048-7e8000d84ea9"
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope('accuracy'):\n",
        "  with tf.name_scope('correct_prediction'):\n",
        "    predictions = tf.argmax(logits, 1)\n",
        "    correct_predictions = tf.equal(predictions, tf.argmax(y_input, 1))\n",
        "  with tf.name_scope('accuracy'):\n",
        "    accuracy_operation = tf.reduce_mean( tf.cast(correct_predictions, tf.float32))\n",
        "tf.summary.scalar('accuracy', accuracy_operation)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'accuracy_1:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "AbfcxvHtgyMI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "Uaf0-zi9g035",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "758bde60-557d-41c9-8988-04f80c84c4a9"
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-27 18:12:33--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.232.181.106, 34.206.130.40, 34.206.253.53, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.232.181.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  21.9MB/s    in 0.2s    \n",
            "\n",
            "2019-01-27 18:12:33 (21.9 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mOUxEmd7gMnD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c1c53da9-50e7-41a1-e3b0-11b138c54572"
      },
      "cell_type": "code",
      "source": [
        "tbc=TensorBoardColab()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://28defb17.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2r9TUHP4gz_s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Wj1Za0NhDt_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2YiO0yeVhKSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "498f1dc4-43a5-4905-ebb0-877aa5058cf9"
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://708f12ad.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nShCrCdEhjzW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f46ab7f6-e68c-4a03-f480-bbdb3e4fc2f4"
      },
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir=/tmp/train --port 6007\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorBoard 1.12.2 at http://1ca6d32057c0:6007 (Press CTRL+C to quit)\n",
            "CTRL+C\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oWXeqYPyZzbs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "merged_summary_operation = tf.summary.merge_all()\n",
        "train_summary_writer = tf.summary.FileWriter('./Graph/train', session.graph)\n",
        "test_summary_writer = tf.summary.FileWriter('./Graph/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bAkErdaNZ8ld",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "\n",
        "test_images, test_labels = mnist_data.test.images, mnist_data.test.labels\n",
        "for batch_no in range(50):\n",
        "  mnist_batch = mnist_data.train.next_batch(16)\n",
        "  train_images, train_labels = mnist_batch[0], mnist_batch[1]\n",
        "  _, merged_summary = session.run([optimiser, merged_summary_operation],\n",
        "  feed_dict={\n",
        "  x_input: train_images,\n",
        "  y_input: train_labels,\n",
        "  dropout_bool: True\n",
        "  })\n",
        "  train_summary_writer.add_summary(merged_summary, batch_no)\n",
        "  if batch_no % 10 == 0:\n",
        "    merged_summary, _ = session.run([merged_summary_operation,\n",
        "    accuracy_operation], feed_dict={\n",
        "    x_input: test_images,\n",
        "    y_input: test_labels,\n",
        "    dropout_bool: False\n",
        "    })\n",
        "    test_summary_writer.add_summary(merged_summary, batch_no)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "__w1OTLofQfH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-owHmcWIOenx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Embedding visualization"
      ]
    },
    {
      "metadata": {
        "id": "rIpcqKmhRE4x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-7dIQ9ozS-ZX",
        "colab_type": "code",
        "outputId": "bf0d563b-46eb-44ef-8f76-67774d886547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JJ_Oemi_RF-P",
        "colab_type": "code",
        "outputId": "4baabb6c-bb85-47fd-be9a-6e01a76bb26b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(mnist_data[::1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f8f0f858f28>, <tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f8f0f88b240>, <tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f8f0f88b390>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b72UNLd-OjT_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "no_embedding_data = 1000\n",
        "embedding_variable = tf.Variable(stack( mnist_data.test.images[:no_embedding_data], axis=0), trainable= False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "REdOhHsTRv6U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### MNIST test data to metadata file for visualization"
      ]
    },
    {
      "metadata": {
        "id": "UzH9iwpBPW33",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metadata_path = '/metadata.tsv'\n",
        "work_dir = ''\n",
        "\n",
        "with open(metadata_path, 'w') as metadata_file:\n",
        "  for i in range(no_embedding_data):\n",
        "    metadata_file.write('{}\\n'.format( np.nonzero(mnist_data.test.labels[::1])[1:][0][i]))\n",
        "    \n",
        "    \n",
        "projector_config =projector.ProjectorConfig()\n",
        "embedding_projection = projector_config.embeddings.add()\n",
        "embedding_projection.tensor_name = embedding_variable.name\n",
        "embedding_projection.metadata_path = metadata_path\n",
        "embedding_projection.sprite.image_path = os.path.join( work_dir + 'mnist_10k_sprite.png')\n",
        "embedding_projection.sprite.single_image_dim.extend([28,28])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BxEQTUFkSsyr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#projector.visualize_embeddings(train_summary_writer, projector_config)\n",
        "#tf.train.Saver().save(session, '/tmp/train/model.ckpt', global_step=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "45Nv7v3xUBuo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}