{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3Imageretrieval.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dasalgadob/handson-machine-learning/blob/master/3Imageretrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c649-5QTOUdK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eeeec942-5111-4b9d-ffec-9872a6eb6c59"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import stack\n",
        "#from keras.datasets import mnist\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from tensorflow.contrib.tensorboard.plugins import projector\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "lLZ8lwl8sudC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Chapter 1 Previous code to chapter 3"
      ]
    },
    {
      "metadata": {
        "id": "MuTdy6sFstSl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "588e07ff-4278-4681-9e4d-daaa190cd82c"
      },
      "cell_type": "code",
      "source": [
        "## Loading\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-d7457694f99a>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gr8Xewc4s6ec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "no_classes = 10\n",
        "batch_size = 100\n",
        "total_batches = 400"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4c9jK_8CtbtL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Placeholders for input data and targets\n",
        "x_input = tf.placeholder(tf.float32, shape=[None, input_size])\n",
        "y_input = tf.placeholder(tf.float32, shape=[None, no_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zvB5k-pSt5E-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights = tf.Variable(tf.random_normal([input_size, no_classes]))\n",
        "bias = tf.Variable(tf.random_normal([no_classes]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RzmVOw5quVI0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logits = tf.matmul(x_input, weights) + bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "huNBlainuWJW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "softmax_cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "labels=y_input, logits=logits)\n",
        "loss_operation = tf.reduce_mean(softmax_cross_entropy)\n",
        "optimiser = tf.train.GradientDescentOptimizer(\n",
        "learning_rate=0.5).minimize(loss_operation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "elmWVX57uxEa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Training the model with data\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "\n",
        "for batch_no in range(total_batches):\n",
        "  mnist_batch = mnist_data.train.next_batch(batch_size)\n",
        "  _, loss_value = session.run([optimiser, loss_operation], feed_dict={\n",
        "  x_input: mnist_batch[0],\n",
        "  y_input: mnist_batch[1]\n",
        "  })\n",
        "  #print(loss_value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5VXajUGgvaLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c7ad0a1-9588-458f-a8ef-511a7ab0ddbc"
      },
      "cell_type": "code",
      "source": [
        "predictions = tf.argmax(logits, 1)\n",
        "correct_predictions = tf.equal(predictions, tf.argmax(y_input, 1))\n",
        "accuracy_operation = tf.reduce_mean(tf.cast(correct_predictions,\n",
        "tf.float32))\n",
        "test_images, test_labels = mnist_data.test.images, mnist_data.test.labels\n",
        "accuracy_value = session.run(accuracy_operation, feed_dict={\n",
        "x_input: test_images,\n",
        "y_input: test_labels\n",
        "})\n",
        "print('Accuracy : ', accuracy_value)\n",
        "session.close()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.8425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Iy96NWGWxFkc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Multilayer convolutional network\n",
        "\n",
        "def add_variable_summary(tf_variable, summary_name):\n",
        "  with tf.name_scope(summary_name + '_summary'):\n",
        "    mean = tf.reduce_mean(tf_variable)\n",
        "    tf.summary.scalar('Mean', mean)\n",
        "    with tf.name_scope('standard_deviation'):\n",
        "      standard_deviation = tf.sqrt(tf.reduce_mean( tf.square(tf_variable - mean)))\n",
        "    tf.summary.scalar('StandardDeviation', standard_deviation)\n",
        "    tf.summary.scalar('Maximum', tf.reduce_max(tf_variable))\n",
        "    tf.summary.scalar('Minimum', tf.reduce_min(tf_variable))\n",
        "    tf.summary.histogram('Histogram', tf_variable)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7BZwfJIpxoT1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_input_reshape = tf.reshape(x_input, [-1, 28, 28, 1],\n",
        "name='input_reshape') ## -1 refers that the batch size could be any"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vAcZZrgwy8j1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-owHmcWIOenx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Embedding visualization"
      ]
    },
    {
      "metadata": {
        "id": "rIpcqKmhRE4x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-7dIQ9ozS-ZX",
        "colab_type": "code",
        "outputId": "bf0d563b-46eb-44ef-8f76-67774d886547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JJ_Oemi_RF-P",
        "colab_type": "code",
        "outputId": "4baabb6c-bb85-47fd-be9a-6e01a76bb26b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(mnist_data[::1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f8f0f858f28>, <tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f8f0f88b240>, <tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f8f0f88b390>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b72UNLd-OjT_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "no_embedding_data = 1000\n",
        "embedding_variable = tf.Variable(stack( mnist_data.test.images[:no_embedding_data], axis=0), trainable= False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "REdOhHsTRv6U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### MNIST test data to metadata file for visualization"
      ]
    },
    {
      "metadata": {
        "id": "UzH9iwpBPW33",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metadata_path = '/metadata.tsv'\n",
        "work_dir = ''\n",
        "\n",
        "with open(metadata_path, 'w') as metadata_file:\n",
        "  for i in range(no_embedding_data):\n",
        "    metadata_file.write('{}\\n'.format( np.nonzero(mnist_data.test.labels[::1])[1:][0][i]))\n",
        "    \n",
        "    \n",
        "projector_config =projector.ProjectorConfig()\n",
        "embedding_projection = projector_config.embeddings.add()\n",
        "embedding_projection.tensor_name = embedding_variable.name\n",
        "embedding_projection.metadata_path = metadata_path\n",
        "embedding_projection.sprite.image_path = os.path.join( work_dir + 'mnist_10k_sprite.png')\n",
        "embedding_projection.sprite.single_image_dim.extend([28,28])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BxEQTUFkSsyr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#projector.visualize_embeddings(train_summary_writer, projector_config)\n",
        "#tf.train.Saver().save(session, '/tmp/train/model.ckpt', global_step=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "45Nv7v3xUBuo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}